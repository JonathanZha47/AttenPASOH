{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/Users/jonathanzha/Desktop/AttenPASOH\")\n",
    "from utils.util import eval_metrix  # Assuming this function exists and is correctly implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AttenPASOH 1\n",
    "This is the attenPASOH including modules as below:\n",
    "- new designed physics loss constraints\n",
    "- 18 to 18 seq 2 seq framework\n",
    "- dynamic weight assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.000102  0.007031  0.003939  0.010114  0.989592  0.003772   \n",
      "1    Experiment2  0.000113  0.007424  0.004125  0.010621  0.988523  0.003983   \n",
      "2    Experiment3  0.000117  0.007650  0.004236  0.010831  0.988064  0.004104   \n",
      "3    Experiment4  0.000111  0.007231  0.004027  0.010559  0.988656  0.003879   \n",
      "4    Experiment5  0.000117  0.008091  0.004463  0.010798  0.988137  0.004340   \n",
      "5    Experiment6  0.000381  0.014335  0.007995  0.019509  0.961276  0.007690   \n",
      "6    Experiment7  0.000138  0.007916  0.004403  0.011757  0.985936  0.004247   \n",
      "7    Experiment8  0.000126  0.007984  0.004429  0.011244  0.987137  0.004283   \n",
      "8    Experiment9  0.000101  0.007346  0.004068  0.010034  0.989756  0.003941   \n",
      "9   Experiment10  0.000241  0.010217  0.005712  0.015520  0.975493  0.005481   \n",
      "10          Mean  0.000155  0.008522  0.004740  0.012099  0.984257  0.004572   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.005418  \n",
      "1   0.005690  \n",
      "2   0.005802  \n",
      "3   0.005657  \n",
      "4   0.005785  \n",
      "5   0.010451  \n",
      "6   0.006299  \n",
      "7   0.006023  \n",
      "8   0.005375  \n",
      "9   0.008314  \n",
      "10  0.006481  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(Seq2seq+0.25weight) results/0-0/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path to the new experiment\n",
    "experiments_path = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(Seq2seq+0.25weight) results/0-0\"\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "# Initialize lists to store metrics for each experiment\n",
    "mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiment in experiments:\n",
    "    true_label_path = os.path.join(experiments_path, experiment, 'true_label.npy')\n",
    "    pred_label_path = os.path.join(experiments_path, experiment, 'pred_label.npy')\n",
    "    \n",
    "    # Calculate metrics for the current experiment\n",
    "    metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "    \n",
    "    mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "    mape_list.append(mape)\n",
    "    rmse_list.append(rmse)\n",
    "    r2_list.append(r2)\n",
    "    l1_list.append(l1)\n",
    "    l2_list.append(l2)\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Experiment': experiments,\n",
    "    'MSE': mse_list,\n",
    "    'MAE': mae_list,\n",
    "    'MAPE': mape_list,\n",
    "    'RMSE': rmse_list,\n",
    "    'R^2': r2_list,\n",
    "    'L1 Error': l1_list,\n",
    "    'L2 Error': l2_list\n",
    "})\n",
    "\n",
    "# Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "# Append the mean values to the DataFrame\n",
    "mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "mean_values_df['Experiment'] = 'Mean'\n",
    "metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "# Print the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_csv_path = os.path.join(experiments_path, 'metrics_summary.csv')\n",
    "metrics_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Metrics summary saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AttenPASOH 2\n",
    "This is the attenPASOH including modules as below:\n",
    "- new designed physics loss constraints\n",
    "- 17 to 17, and 17 to 1 MLP predict\n",
    "- dynamic weight assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.000233  0.012076  0.006565  0.015258  0.976314  0.006478   \n",
      "1    Experiment2  0.000115  0.007598  0.004228  0.010705  0.988341  0.004076   \n",
      "2    Experiment3  0.000436  0.013615  0.007681  0.020870  0.955683  0.007304   \n",
      "3    Experiment4  0.000294  0.011920  0.006630  0.017141  0.970106  0.006395   \n",
      "4    Experiment5  0.000321  0.015204  0.008241  0.017903  0.967391  0.008157   \n",
      "5    Experiment6  0.000157  0.008695  0.004839  0.012535  0.984013  0.004665   \n",
      "6    Experiment7  0.000156  0.008195  0.004577  0.012478  0.984159  0.004396   \n",
      "7    Experiment8  0.000145  0.007804  0.004378  0.012048  0.985231  0.004186   \n",
      "8    Experiment9  0.000195  0.009781  0.005454  0.013952  0.980194  0.005247   \n",
      "9   Experiment10  0.000161  0.008517  0.004759  0.012707  0.983571  0.004569   \n",
      "10          Mean  0.000221  0.010341  0.005735  0.014560  0.977500  0.005547   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.008174  \n",
      "1   0.005735  \n",
      "2   0.011180  \n",
      "3   0.009183  \n",
      "4   0.009591  \n",
      "5   0.006715  \n",
      "6   0.006685  \n",
      "7   0.006454  \n",
      "8   0.007474  \n",
      "9   0.006807  \n",
      "10  0.007800  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results/0-0/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path to the new experiment\n",
    "experiments_path = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results/0-0\"\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "# Initialize lists to store metrics for each experiment\n",
    "mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiment in experiments:\n",
    "    true_label_path = os.path.join(experiments_path, experiment, 'true_label.npy')\n",
    "    pred_label_path = os.path.join(experiments_path, experiment, 'pred_label.npy')\n",
    "    \n",
    "    # Calculate metrics for the current experiment\n",
    "    metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "    \n",
    "    mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "    mape_list.append(mape)\n",
    "    rmse_list.append(rmse)\n",
    "    r2_list.append(r2)\n",
    "    l1_list.append(l1)\n",
    "    l2_list.append(l2)\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Experiment': experiments,\n",
    "    'MSE': mse_list,\n",
    "    'MAE': mae_list,\n",
    "    'MAPE': mape_list,\n",
    "    'RMSE': rmse_list,\n",
    "    'R^2': r2_list,\n",
    "    'L1 Error': l1_list,\n",
    "    'L2 Error': l2_list\n",
    "})\n",
    "\n",
    "# Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "# Append the mean values to the DataFrame\n",
    "mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "mean_values_df['Experiment'] = 'Mean'\n",
    "metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "# Print the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_csv_path = os.path.join(experiments_path, 'metrics_summary.csv')\n",
    "metrics_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Metrics summary saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.002998  0.003313  0.000014  0.003693  0.994333  0.003204   \n",
      "1    Experiment2  0.019438  0.021473  0.000570  0.023867  0.763358  0.020773   \n",
      "2    Experiment3  0.007169  0.007917  0.000077  0.008799  0.967837  0.007662   \n",
      "3    Experiment4  0.013393  0.014794  0.000271  0.016453  0.887539  0.014314   \n",
      "4    Experiment5  0.002452  0.002710  0.000009  0.003023  0.996204  0.002621   \n",
      "5    Experiment6  0.016646  0.018388  0.000417  0.020430  0.826599  0.017790   \n",
      "6    Experiment7  0.019824  0.021905  0.000595  0.024386  0.752956  0.021186   \n",
      "7    Experiment8  0.019287  0.021313  0.000563  0.023731  0.766053  0.020612   \n",
      "8    Experiment9  0.017439  0.019265  0.000459  0.021414  0.809491  0.018637   \n",
      "9   Experiment10  0.029097  0.032150  0.001279  0.035769  0.468499  0.031097   \n",
      "10          Mean  0.014774  0.016323  0.000425  0.018156  0.823287  0.015790   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.003942  \n",
      "1   0.025472  \n",
      "2   0.009391  \n",
      "3   0.017560  \n",
      "4   0.003226  \n",
      "5   0.021804  \n",
      "6   0.026026  \n",
      "7   0.025326  \n",
      "8   0.022854  \n",
      "9   0.038174  \n",
      "10  0.019377  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(dlinear) results/0-0/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.005462  0.005958  0.000052  0.007206  0.959795  0.005821   \n",
      "1    Experiment2  0.005729  0.006269  0.000060  0.007715  0.953916  0.006105   \n",
      "2    Experiment3  0.021473  0.023406  0.000794  0.028185  0.384948  0.022883   \n",
      "3    Experiment4  0.006655  0.007243  0.000078  0.008841  0.939477  0.007092   \n",
      "4    Experiment5  0.031394  0.034222  0.001697  0.041199 -0.314186  0.033455   \n",
      "5    Experiment6  0.010365  0.011307  0.000187  0.013669  0.855325  0.011046   \n",
      "6    Experiment7  0.001903  0.002074  0.000006  0.002497  0.995171  0.002028   \n",
      "7    Experiment8  0.010466  0.011411  0.000189  0.013747  0.853676  0.011154   \n",
      "8    Experiment9  0.006663  0.007265  0.000077  0.008773  0.940412  0.007100   \n",
      "9   Experiment10  0.017564  0.019144  0.000531  0.023042  0.588927  0.018717   \n",
      "10          Mean  0.011767  0.012830  0.000367  0.015487  0.715746  0.012540   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.007674  \n",
      "1   0.008216  \n",
      "2   0.030013  \n",
      "3   0.009415  \n",
      "4   0.043872  \n",
      "5   0.014556  \n",
      "6   0.002659  \n",
      "7   0.014639  \n",
      "8   0.009342  \n",
      "9   0.024537  \n",
      "10  0.016492  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(dlinear) results/1-1/metrics_summary.csv\n",
      "      Experiment       MSE       MAE          MAPE      RMSE       R^2  \\\n",
      "0    Experiment1  0.005241  0.005663  4.112394e-05  0.006413  0.980796   \n",
      "1    Experiment2  0.016418  0.017783  4.072358e-04  0.020180  0.809828   \n",
      "2    Experiment3  0.002323  0.002509  8.061272e-06  0.002839  0.996236   \n",
      "3    Experiment4  0.022806  0.024707  7.865936e-04  0.028046  0.632674   \n",
      "4    Experiment5  0.024114  0.026103  8.763035e-04  0.029602  0.590782   \n",
      "5    Experiment6  0.007412  0.008003  8.203420e-05  0.009057  0.961691   \n",
      "6    Experiment7  0.000261  0.000282  1.026298e-07  0.000320  0.999952   \n",
      "7    Experiment8  0.011513  0.012461  1.996577e-04  0.014130  0.906763   \n",
      "8    Experiment9  0.013614  0.014737  2.793065e-04  0.016712  0.869569   \n",
      "9   Experiment10  0.006969  0.007551  7.365653e-05  0.008582  0.965604   \n",
      "10          Mean  0.011067  0.011980  2.754075e-04  0.013588  0.871389   \n",
      "\n",
      "    L1 Error  L2 Error  \n",
      "0   0.005553  0.006787  \n",
      "1   0.017398  0.021359  \n",
      "2   0.002462  0.003005  \n",
      "3   0.024166  0.029684  \n",
      "4   0.025553  0.031331  \n",
      "5   0.007854  0.009586  \n",
      "6   0.000276  0.000339  \n",
      "7   0.012200  0.014955  \n",
      "8   0.014426  0.017689  \n",
      "9   0.007385  0.009084  \n",
      "10  0.011727  0.014382  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(dlinear) results/2-2/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.002821  0.003085  0.000014  0.003738  0.993574  0.002999   \n",
      "1    Experiment2  0.032346  0.035381  0.001838  0.042875  0.154509  0.034392   \n",
      "2    Experiment3  0.025276  0.027651  0.001124  0.033519  0.483236  0.026874   \n",
      "3    Experiment4  0.004537  0.004968  0.000037  0.006111  0.982822  0.004824   \n",
      "4    Experiment5  0.027605  0.030183  0.001336  0.036553  0.385453  0.029350   \n",
      "5    Experiment6  0.010777  0.011796  0.000206  0.014336  0.905468  0.011459   \n",
      "6    Experiment7  0.003334  0.003642  0.000020  0.004468  0.990818  0.003545   \n",
      "7    Experiment8  0.003201  0.003501  0.000019  0.004324  0.991400  0.003404   \n",
      "8    Experiment9  0.018290  0.020012  0.000589  0.024271  0.729046  0.019447   \n",
      "9   Experiment10  0.010497  0.011481  0.000193  0.013910  0.911001  0.011161   \n",
      "10          Mean  0.013868  0.015170  0.000538  0.018411  0.752733  0.014745   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.003969  \n",
      "1   0.045530  \n",
      "2   0.035595  \n",
      "3   0.006490  \n",
      "4   0.038817  \n",
      "5   0.015224  \n",
      "6   0.004745  \n",
      "7   0.004592  \n",
      "8   0.025775  \n",
      "9   0.014772  \n",
      "10  0.019551  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(dlinear) results/3-3/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.019910  0.021446  0.000556  0.023587  0.460447  0.021187   \n",
      "1    Experiment2  0.002301  0.002507  0.000028  0.005333  0.972418  0.002449   \n",
      "2    Experiment3  0.004912  0.005254  0.000044  0.006668  0.956886  0.005227   \n",
      "3    Experiment4  0.013280  0.014283  0.000244  0.015627  0.763167  0.014132   \n",
      "4    Experiment5  0.003906  0.004227  0.000030  0.005449  0.971201  0.004156   \n",
      "5    Experiment6  0.016300  0.017576  0.000379  0.019462  0.632664  0.017346   \n",
      "6    Experiment7  0.015829  0.017055  0.000353  0.018783  0.657856  0.016845   \n",
      "7    Experiment8  0.026264  0.028290  0.000966  0.031080  0.063218  0.027949   \n",
      "8    Experiment9  0.010939  0.011788  0.000170  0.013020  0.835594  0.011641   \n",
      "9   Experiment10  0.010831  0.011673  0.000166  0.012872  0.839305  0.011525   \n",
      "10          Mean  0.012447  0.013410  0.000294  0.015188  0.715276  0.013246   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.025086  \n",
      "1   0.005672  \n",
      "2   0.007091  \n",
      "3   0.016620  \n",
      "4   0.005796  \n",
      "5   0.020699  \n",
      "6   0.019976  \n",
      "7   0.033054  \n",
      "8   0.013847  \n",
      "9   0.013690  \n",
      "10  0.016153  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(dlinear) results/4-4/metrics_summary.csv\n",
      "      Experiment       MSE       MAE          MAPE      RMSE       R^2  \\\n",
      "0    Experiment1  0.012459  0.013417  2.727507e-04  0.016515  0.786796   \n",
      "1    Experiment2  0.006574  0.007051  7.426291e-05  0.008618  0.941950   \n",
      "2    Experiment3  0.010482  0.011251  1.895808e-04  0.013769  0.851808   \n",
      "3    Experiment4  0.017836  0.019149  5.496296e-04  0.023444  0.570364   \n",
      "4    Experiment5  0.005148  0.005526  4.572702e-05  0.006762  0.964256   \n",
      "5    Experiment6  0.000651  0.000696  1.931915e-06  0.001390  0.998490   \n",
      "6    Experiment7  0.000675  0.000727  7.970452e-07  0.000893  0.999377   \n",
      "7    Experiment8  0.020082  0.021560  6.966588e-04  0.026394  0.455434   \n",
      "8    Experiment9  0.028481  0.030581  1.402055e-03  0.037444 -0.095962   \n",
      "9   Experiment10  0.012970  0.013913  2.892629e-04  0.017008  0.773888   \n",
      "10          Mean  0.011536  0.012387  3.522657e-04  0.015224  0.724640   \n",
      "\n",
      "    L1 Error  L2 Error  \n",
      "0   0.013168  0.017443  \n",
      "1   0.006948  0.009102  \n",
      "2   0.011078  0.014542  \n",
      "3   0.018851  0.024761  \n",
      "4   0.005441  0.007142  \n",
      "5   0.000688  0.001468  \n",
      "6   0.000714  0.000943  \n",
      "7   0.021225  0.027877  \n",
      "8   0.030103  0.039547  \n",
      "9   0.013709  0.017963  \n",
      "10  0.012193  0.016079  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(dlinear) results/5-5/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the new experiment\n",
    "experiments_path_Dlinear = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(dlinear) results\"\n",
    "\n",
    "experiments_path_Dlinears = [os.path.join(experiments_path_Dlinear, f\"{i}-{i}\") for i in range(6)]\n",
    "\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiments_path_Dlinear in experiments_path_Dlinears:\n",
    "    # Initialize lists to store metrics for each experiment\n",
    "    mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "    for experiment in experiments:\n",
    "        true_label_path = os.path.join(experiments_path_Dlinear, experiment, 'true_label.npy')\n",
    "        pred_label_path = os.path.join(experiments_path_Dlinear, experiment, 'pred_label.npy')\n",
    "        \n",
    "        # Calculate metrics for the current experiment\n",
    "        metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "        \n",
    "        mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        mape_list.append(mape)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "        l1_list.append(l1)\n",
    "        l2_list.append(l2)\n",
    "\n",
    "    # Create a DataFrame to store the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Experiment': experiments,\n",
    "        'MSE': mse_list,\n",
    "        'MAE': mae_list,\n",
    "        'MAPE': mape_list,\n",
    "        'RMSE': rmse_list,\n",
    "        'R^2': r2_list,\n",
    "        'L1 Error': l1_list,\n",
    "        'L2 Error': l2_list\n",
    "    })\n",
    "\n",
    "    # Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "    mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "    # Append the mean values to the DataFrame\n",
    "    mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "    mean_values_df['Experiment'] = 'Mean'\n",
    "    metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "    # Print the results\n",
    "    print(metrics_df)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    output_csv_path = os.path.join(experiments_path_Dlinear, 'metrics_summary.csv')\n",
    "    metrics_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Metrics summary saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.008003  0.008752  0.000118  0.010845  0.952197  0.008578   \n",
      "1    Experiment2  0.019888  0.022000  0.000791  0.028124  0.678506  0.021316   \n",
      "2    Experiment3  0.015839  0.017361  0.000577  0.024028  0.765328  0.016976   \n",
      "3    Experiment4  0.033802  0.037733  0.001889  0.043459  0.232316  0.036228   \n",
      "4    Experiment5  0.018292  0.020450  0.000757  0.027512  0.692346  0.019605   \n",
      "5    Experiment6  0.020082  0.021902  0.000595  0.024396  0.758092  0.021523   \n",
      "6    Experiment7  0.033265  0.036966  0.001828  0.042759  0.256848  0.035652   \n",
      "7    Experiment8  0.021366  0.024260  0.001084  0.032924  0.559393  0.022900   \n",
      "8    Experiment9  0.010702  0.011551  0.000177  0.013309  0.927999  0.011471   \n",
      "9   Experiment10  0.019252  0.021180  0.000697  0.026404  0.716616  0.020634   \n",
      "10          Mean  0.020049  0.022215  0.000851  0.027376  0.653964  0.021488   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.011607  \n",
      "1   0.030100  \n",
      "2   0.025716  \n",
      "3   0.046513  \n",
      "4   0.029445  \n",
      "5   0.026110  \n",
      "6   0.045763  \n",
      "7   0.035237  \n",
      "8   0.014245  \n",
      "9   0.028260  \n",
      "10  0.029300  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(crossformer,seq_len=50) results/0-0/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.015183  0.016273  0.000299  0.017283  0.785806  0.016193   \n",
      "1    Experiment2  0.017241  0.018453  0.000373  0.019320  0.732334  0.018388   \n",
      "2    Experiment3  0.029265  0.031806  0.001362  0.036901  0.023545  0.031212   \n",
      "3    Experiment4  0.028427  0.031171  0.001408  0.037521 -0.009542  0.030318   \n",
      "4    Experiment5  0.016423  0.017506  0.000374  0.019337  0.731873  0.017516   \n",
      "5    Experiment6  0.015834  0.016939  0.000332  0.018226  0.761796  0.016888   \n",
      "6    Experiment7  0.015136  0.016113  0.000324  0.018003  0.767594  0.016143   \n",
      "7    Experiment8  0.028043  0.030621  0.001316  0.036281  0.056074  0.029909   \n",
      "8    Experiment9  0.016133  0.017452  0.000412  0.020287  0.704887  0.017207   \n",
      "9   Experiment10  0.015714  0.016793  0.000361  0.019008  0.740922  0.016760   \n",
      "10          Mean  0.019740  0.021313  0.000656  0.024217  0.529529  0.021053   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.018418  \n",
      "1   0.020589  \n",
      "2   0.039325  \n",
      "3   0.039986  \n",
      "4   0.020607  \n",
      "5   0.019423  \n",
      "6   0.019185  \n",
      "7   0.038665  \n",
      "8   0.021619  \n",
      "9   0.020256  \n",
      "10  0.025807  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(crossformer,seq_len=50) results/1-1/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.018046  0.019965  0.000756  0.027494  0.645796  0.019164   \n",
      "1    Experiment2  0.030115  0.033471  0.001723  0.041509  0.192647  0.031981   \n",
      "2    Experiment3  0.015696  0.016992  0.000444  0.021060  0.792181  0.016668   \n",
      "3    Experiment4  0.035644  0.038631  0.001972  0.044411  0.075812  0.037853   \n",
      "4    Experiment5  0.035426  0.038313  0.001958  0.044251  0.082446  0.037621   \n",
      "5    Experiment6  0.008251  0.008854  0.000137  0.011710  0.935750  0.008763   \n",
      "6    Experiment7  0.018168  0.019807  0.000648  0.025453  0.696420  0.019294   \n",
      "7    Experiment8  0.014085  0.015231  0.000441  0.021000  0.793358  0.014957   \n",
      "8    Experiment9  0.030438  0.033575  0.001707  0.041317  0.200108  0.032324   \n",
      "9   Experiment10  0.017858  0.019497  0.000644  0.025373  0.698327  0.018965   \n",
      "10          Mean  0.022373  0.024433  0.001043  0.030358  0.511285  0.023759   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.029162  \n",
      "1   0.044028  \n",
      "2   0.022338  \n",
      "3   0.047106  \n",
      "4   0.046937  \n",
      "5   0.012420  \n",
      "6   0.026998  \n",
      "7   0.022274  \n",
      "8   0.043824  \n",
      "9   0.026913  \n",
      "10  0.032200  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(crossformer,seq_len=50) results/2-2/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.009766  0.010778  0.000292  0.017102  0.864566  0.010406   \n",
      "1    Experiment2  0.006676  0.007435  0.000149  0.012201  0.931064  0.007114   \n",
      "2    Experiment3  0.011971  0.013386  0.000474  0.021774  0.780444  0.012755   \n",
      "3    Experiment4  0.015657  0.017122  0.000524  0.022883  0.757512  0.016683   \n",
      "4    Experiment5  0.006084  0.006865  0.000130  0.011423  0.939573  0.006482   \n",
      "5    Experiment6  0.008446  0.009386  0.000226  0.015045  0.895182  0.009000   \n",
      "6    Experiment7  0.004947  0.005477  0.000080  0.008955  0.962868  0.005271   \n",
      "7    Experiment8  0.006082  0.006692  0.000105  0.010259  0.951260  0.006481   \n",
      "8    Experiment9  0.007282  0.007955  0.000149  0.012188  0.931215  0.007759   \n",
      "9   Experiment10  0.005842  0.006454  0.000097  0.009848  0.955086  0.006225   \n",
      "10          Mean  0.008275  0.009155  0.000223  0.014168  0.896877  0.008818   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.018200  \n",
      "1   0.012985  \n",
      "2   0.023173  \n",
      "3   0.024353  \n",
      "4   0.012157  \n",
      "5   0.016011  \n",
      "6   0.009530  \n",
      "7   0.010918  \n",
      "8   0.012970  \n",
      "9   0.010481  \n",
      "10  0.015078  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(crossformer,seq_len=50) results/3-3/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.026279  0.028536  0.001025  0.032018  0.028068  0.028106   \n",
      "1    Experiment2  0.024728  0.026905  0.000947  0.030773  0.102174  0.026446   \n",
      "2    Experiment3  0.026395  0.028625  0.001024  0.032003  0.029017  0.028229   \n",
      "3    Experiment4  0.024408  0.026811  0.001064  0.032613 -0.008409  0.026105   \n",
      "4    Experiment5  0.026254  0.028469  0.001008  0.031746  0.044530  0.028079   \n",
      "5    Experiment6  0.024267  0.026625  0.001032  0.032117  0.022040  0.025953   \n",
      "6    Experiment7  0.031055  0.033365  0.001264  0.035552 -0.198287  0.033213   \n",
      "7    Experiment8  0.030628  0.032844  0.001231  0.035079 -0.166630  0.032757   \n",
      "8    Experiment9  0.026154  0.028436  0.001031  0.032108  0.022621  0.027972   \n",
      "9   Experiment10  0.031620  0.033947  0.001295  0.035981 -0.227415  0.033817   \n",
      "10          Mean  0.027179  0.029456  0.001092  0.032999 -0.035229  0.029068   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.034223  \n",
      "1   0.032892  \n",
      "2   0.034206  \n",
      "3   0.034859  \n",
      "4   0.033932  \n",
      "5   0.034329  \n",
      "6   0.038000  \n",
      "7   0.037494  \n",
      "8   0.034319  \n",
      "9   0.038459  \n",
      "10  0.035271  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(crossformer,seq_len=50) results/4-4/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.006600  0.007249  0.000135  0.011620  0.893740  0.006985   \n",
      "1    Experiment2  0.013256  0.014283  0.000360  0.018983  0.716415  0.014031   \n",
      "2    Experiment3  0.011446  0.012454  0.000353  0.018775  0.722572  0.012114   \n",
      "3    Experiment4  0.008687  0.009486  0.000257  0.016019  0.798040  0.009195   \n",
      "4    Experiment5  0.023127  0.025079  0.000809  0.028444  0.363264  0.024478   \n",
      "5    Experiment6  0.007976  0.008685  0.000174  0.013199  0.862897  0.008442   \n",
      "6    Experiment7  0.010737  0.011624  0.000302  0.017378  0.762331  0.011364   \n",
      "7    Experiment8  0.013387  0.014478  0.000407  0.020167  0.679927  0.014169   \n",
      "8    Experiment9  0.011457  0.012427  0.000324  0.018001  0.744982  0.012126   \n",
      "9   Experiment10  0.024946  0.027051  0.001150  0.033914  0.094802  0.026404   \n",
      "10          Mean  0.013162  0.014282  0.000427  0.019650  0.663897  0.013931   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.012290  \n",
      "1   0.020077  \n",
      "2   0.019858  \n",
      "3   0.016943  \n",
      "4   0.030084  \n",
      "5   0.013960  \n",
      "6   0.018380  \n",
      "7   0.021330  \n",
      "8   0.019039  \n",
      "9   0.035870  \n",
      "10  0.020783  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(crossformer,seq_len=50) results/5-5/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the new experiment\n",
    "experiments_path_crossformer = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(crossformer,seq_len=50) results\"\n",
    "\n",
    "experiments_path_crossformers = [os.path.join(experiments_path_crossformer, f\"{i}-{i}\") for i in range(6)]\n",
    "\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiments_path_crossformer in experiments_path_crossformers:\n",
    "    # Initialize lists to store metrics for each experiment\n",
    "    mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "    for experiment in experiments:\n",
    "        true_label_path = os.path.join(experiments_path_crossformer, experiment, 'true_label.npy')\n",
    "        pred_label_path = os.path.join(experiments_path_crossformer, experiment, 'pred_label.npy')\n",
    "        \n",
    "        # Calculate metrics for the current experiment\n",
    "        metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "        \n",
    "        mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        mape_list.append(mape)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "        l1_list.append(l1)\n",
    "        l2_list.append(l2)\n",
    "\n",
    "    # Create a DataFrame to store the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Experiment': experiments,\n",
    "        'MSE': mse_list,\n",
    "        'MAE': mae_list,\n",
    "        'MAPE': mape_list,\n",
    "        'RMSE': rmse_list,\n",
    "        'R^2': r2_list,\n",
    "        'L1 Error': l1_list,\n",
    "        'L2 Error': l2_list\n",
    "    })\n",
    "\n",
    "    # Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "    mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "    # Append the mean values to the DataFrame\n",
    "    mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "    mean_values_df['Experiment'] = 'Mean'\n",
    "    metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "    # Print the results\n",
    "    print(metrics_df)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    output_csv_path = os.path.join(experiments_path_crossformer, 'metrics_summary.csv')\n",
    "    metrics_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Metrics summary saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.000945  0.001042  0.000002  0.001293  0.999305  0.001009   \n",
      "1    Experiment2  0.003183  0.003515  0.000016  0.004002  0.993342  0.003402   \n",
      "2    Experiment3  0.003525  0.003897  0.000019  0.004386  0.992003  0.003767   \n",
      "3    Experiment4  0.002783  0.003073  0.000012  0.003477  0.994975  0.002974   \n",
      "4    Experiment5  0.003748  0.004144  0.000022  0.004727  0.990712  0.004006   \n",
      "5    Experiment6  0.006877  0.007598  0.000073  0.008535  0.969722  0.007350   \n",
      "6    Experiment7  0.005098  0.005632  0.000040  0.006363  0.983172  0.005448   \n",
      "7    Experiment8  0.004156  0.004594  0.000027  0.005228  0.988638  0.004442   \n",
      "8    Experiment9  0.003626  0.004007  0.000020  0.004512  0.991536  0.003875   \n",
      "9   Experiment10  0.001804  0.001994  0.000005  0.002296  0.997809  0.001928   \n",
      "10          Mean  0.003575  0.003950  0.000024  0.004482  0.990121  0.003820   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.001380  \n",
      "1   0.004271  \n",
      "2   0.004681  \n",
      "3   0.003711  \n",
      "4   0.005045  \n",
      "5   0.009108  \n",
      "6   0.006790  \n",
      "7   0.005580  \n",
      "8   0.004816  \n",
      "9   0.002450  \n",
      "10  0.004783  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(itransformer_seq=2) results/0-0/metrics_summary.csv\n",
      "      Experiment       MSE       MAE          MAPE      RMSE       R^2  \\\n",
      "0    Experiment1  0.001291  0.001402  2.928738e-06  0.001711  0.997753   \n",
      "1    Experiment2  0.004137  0.004516  2.998325e-05  0.005476  0.977001   \n",
      "2    Experiment3  0.003898  0.004254  2.657564e-05  0.005155  0.979615   \n",
      "3    Experiment4  0.001915  0.002089  6.389632e-06  0.002528  0.995099   \n",
      "4    Experiment5  0.003303  0.003601  1.893708e-05  0.004352  0.985474   \n",
      "5    Experiment6  0.000312  0.000338  1.660587e-07  0.000408  0.999873   \n",
      "6    Experiment7  0.003150  0.003435  1.720575e-05  0.004148  0.986802   \n",
      "7    Experiment8  0.002319  0.002528  9.423518e-06  0.003070  0.992772   \n",
      "8    Experiment9  0.000512  0.000556  4.749651e-07  0.000689  0.999636   \n",
      "9   Experiment10  0.001803  0.001960  5.811264e-06  0.002411  0.995542   \n",
      "10          Mean  0.002264  0.002468  1.178959e-05  0.002995  0.990957   \n",
      "\n",
      "    L1 Error  L2 Error  \n",
      "0   0.001376  0.001823  \n",
      "1   0.004409  0.005832  \n",
      "2   0.004154  0.005490  \n",
      "3   0.002040  0.002692  \n",
      "4   0.003520  0.004634  \n",
      "5   0.000333  0.000434  \n",
      "6   0.003357  0.004418  \n",
      "7   0.002471  0.003269  \n",
      "8   0.000546  0.000734  \n",
      "9   0.001921  0.002567  \n",
      "10  0.002413  0.003189  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(itransformer_seq=2) results/1-1/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.003989  0.004321  0.000025  0.004992  0.988353  0.004227   \n",
      "1    Experiment2  0.006285  0.006800  0.000062  0.007888  0.970915  0.006660   \n",
      "2    Experiment3  0.004328  0.004599  0.000027  0.005199  0.987367  0.004587   \n",
      "3    Experiment4  0.002512  0.002731  0.000010  0.003218  0.995159  0.002662   \n",
      "4    Experiment5  0.005835  0.006322  0.000055  0.007410  0.974339  0.006183   \n",
      "5    Experiment6  0.001062  0.001151  0.000002  0.001335  0.999167  0.001125   \n",
      "6    Experiment7  0.002854  0.003093  0.000013  0.003549  0.994113  0.003024   \n",
      "7    Experiment8  0.004507  0.004890  0.000031  0.005581  0.985444  0.004776   \n",
      "8    Experiment9  0.002433  0.002631  0.000009  0.003016  0.995749  0.002578   \n",
      "9   Experiment10  0.003055  0.003305  0.000014  0.003788  0.993292  0.003237   \n",
      "10          Mean  0.003686  0.003984  0.000025  0.004598  0.988390  0.003906   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.005283  \n",
      "1   0.008349  \n",
      "2   0.005502  \n",
      "3   0.003406  \n",
      "4   0.007842  \n",
      "5   0.001413  \n",
      "6   0.003756  \n",
      "7   0.005906  \n",
      "8   0.003192  \n",
      "9   0.004009  \n",
      "10  0.004866  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(itransformer_seq=2) results/2-2/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.001513  0.001639  0.000004  0.001877  0.998379  0.001609   \n",
      "1    Experiment2  0.004300  0.004688  0.000031  0.005578  0.985683  0.004572   \n",
      "2    Experiment3  0.003290  0.003578  0.000018  0.004224  0.991789  0.003498   \n",
      "3    Experiment4  0.004482  0.004858  0.000033  0.005764  0.984712  0.004765   \n",
      "4    Experiment5  0.002802  0.003049  0.000013  0.003560  0.994167  0.002979   \n",
      "5    Experiment6  0.002446  0.002659  0.000009  0.003080  0.995635  0.002601   \n",
      "6    Experiment7  0.004368  0.004757  0.000032  0.005659  0.985264  0.004644   \n",
      "7    Experiment8  0.002518  0.002745  0.000010  0.003237  0.995177  0.002677   \n",
      "8    Experiment9  0.000859  0.000933  0.000001  0.001074  0.999470  0.000914   \n",
      "9   Experiment10  0.006891  0.007575  0.000087  0.009327  0.959966  0.007326   \n",
      "10          Mean  0.003347  0.003648  0.000024  0.004338  0.989024  0.003558   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.001993  \n",
      "1   0.005923  \n",
      "2   0.004486  \n",
      "3   0.006121  \n",
      "4   0.003781  \n",
      "5   0.003270  \n",
      "6   0.006009  \n",
      "7   0.003438  \n",
      "8   0.001140  \n",
      "9   0.009905  \n",
      "10  0.004607  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(itransformer_seq=2) results/3-3/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.003173  0.003423  0.000015  0.003837  0.985687  0.003376   \n",
      "1    Experiment2  0.001961  0.002095  0.000036  0.006029  0.964667  0.002087   \n",
      "2    Experiment3  0.002109  0.002285  0.000007  0.002627  0.993291  0.002244   \n",
      "3    Experiment4  0.006586  0.007055  0.000063  0.007967  0.938310  0.007008   \n",
      "4    Experiment5  0.003606  0.003903  0.000020  0.004440  0.980838  0.003837   \n",
      "5    Experiment6  0.003203  0.003440  0.000022  0.004639  0.979083  0.003408   \n",
      "6    Experiment7  0.000790  0.000871  0.000003  0.001862  0.996630  0.000841   \n",
      "7    Experiment8  0.003392  0.003669  0.000017  0.004152  0.983241  0.003609   \n",
      "8    Experiment9  0.001571  0.001686  0.000007  0.002713  0.992846  0.001672   \n",
      "9   Experiment10  0.001380  0.001466  0.000021  0.004558  0.979803  0.001469   \n",
      "10          Mean  0.002777  0.002989  0.000021  0.004282  0.979440  0.002955   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.004081  \n",
      "1   0.006412  \n",
      "2   0.002794  \n",
      "3   0.008472  \n",
      "4   0.004722  \n",
      "5   0.004933  \n",
      "6   0.001980  \n",
      "7   0.004416  \n",
      "8   0.002885  \n",
      "9   0.004848  \n",
      "10  0.004554  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(itransformer_seq=2) results/4-4/metrics_summary.csv\n",
      "      Experiment       MSE       MAE          MAPE      RMSE       R^2  \\\n",
      "0    Experiment1  0.001563  0.001687  5.104820e-06  0.002259  0.996007   \n",
      "1    Experiment2  0.001980  0.002126  6.637837e-06  0.002576  0.994808   \n",
      "2    Experiment3  0.004106  0.004410  2.845648e-05  0.005334  0.977743   \n",
      "3    Experiment4  0.005691  0.006113  5.541879e-05  0.007444  0.956654   \n",
      "4    Experiment5  0.000783  0.000840  1.317292e-06  0.001148  0.998970   \n",
      "5    Experiment6  0.000514  0.000553  4.591182e-07  0.000678  0.999641   \n",
      "6    Experiment7  0.003618  0.003886  2.229618e-05  0.004722  0.982561   \n",
      "7    Experiment8  0.002724  0.002925  1.250921e-05  0.003537  0.990216   \n",
      "8    Experiment9  0.005454  0.005857  5.089646e-05  0.007134  0.960191   \n",
      "9   Experiment10  0.004741  0.005091  3.832566e-05  0.006191  0.970023   \n",
      "10          Mean  0.003117  0.003349  2.214218e-05  0.004102  0.982681   \n",
      "\n",
      "    L1 Error  L2 Error  \n",
      "0   0.001652  0.002386  \n",
      "1   0.002093  0.002721  \n",
      "2   0.004340  0.005634  \n",
      "3   0.006015  0.007862  \n",
      "4   0.000827  0.001212  \n",
      "5   0.000544  0.000716  \n",
      "6   0.003824  0.004987  \n",
      "7   0.002879  0.003735  \n",
      "8   0.005764  0.007535  \n",
      "9   0.005011  0.006538  \n",
      "10  0.003295  0.004333  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(itransformer_seq=2) results/5-5/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the new experiment\n",
    "experiments_path_itransformer = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(itransformer_seq=2) results\"\n",
    "\n",
    "experiments_path_itransformers = [os.path.join(experiments_path_itransformer, f\"{i}-{i}\") for i in range(6)]\n",
    "\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiments_path_itransformer in experiments_path_itransformers:\n",
    "    # Initialize lists to store metrics for each experiment\n",
    "    mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "    for experiment in experiments:\n",
    "        true_label_path = os.path.join(experiments_path_itransformer, experiment, 'true_label.npy')\n",
    "        pred_label_path = os.path.join(experiments_path_itransformer, experiment, 'pred_label.npy')\n",
    "        \n",
    "        # Calculate metrics for the current experiment\n",
    "        metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "        \n",
    "        mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        mape_list.append(mape)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "        l1_list.append(l1)\n",
    "        l2_list.append(l2)\n",
    "\n",
    "    # Create a DataFrame to store the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Experiment': experiments,\n",
    "        'MSE': mse_list,\n",
    "        'MAE': mae_list,\n",
    "        'MAPE': mape_list,\n",
    "        'RMSE': rmse_list,\n",
    "        'R^2': r2_list,\n",
    "        'L1 Error': l1_list,\n",
    "        'L2 Error': l2_list\n",
    "    })\n",
    "\n",
    "    # Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "    mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "    # Append the mean values to the DataFrame\n",
    "    mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "    mean_values_df['Experiment'] = 'Mean'\n",
    "    metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "    # Print the results\n",
    "    print(metrics_df)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    output_csv_path = os.path.join(experiments_path_itransformer, 'metrics_summary.csv')\n",
    "    metrics_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Metrics summary saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AttenPASOH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

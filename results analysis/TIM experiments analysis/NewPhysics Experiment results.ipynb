{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/Users/jonathanzha/Desktop/AttenPASOH\")\n",
    "from utils.util import eval_metrix  # Assuming this function exists and is correctly implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.012076  0.006565  0.000233  0.015258  0.976314  0.006478   \n",
      "1    Experiment2  0.007598  0.004228  0.000115  0.010705  0.988341  0.004076   \n",
      "2    Experiment3  0.013615  0.007681  0.000436  0.020870  0.955683  0.007304   \n",
      "3    Experiment4  0.011920  0.006630  0.000294  0.017141  0.970106  0.006395   \n",
      "4    Experiment5  0.015204  0.008241  0.000321  0.017903  0.967391  0.008157   \n",
      "5    Experiment6  0.008695  0.004839  0.000157  0.012535  0.984013  0.004665   \n",
      "6    Experiment7  0.008195  0.004577  0.000156  0.012478  0.984159  0.004396   \n",
      "7    Experiment8  0.007804  0.004378  0.000145  0.012048  0.985231  0.004186   \n",
      "8    Experiment9  0.009781  0.005454  0.000195  0.013952  0.980194  0.005247   \n",
      "9   Experiment10  0.008517  0.004759  0.000161  0.012707  0.983571  0.004569   \n",
      "10          Mean  0.010341  0.005735  0.000221  0.014560  0.977500  0.005547   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.008174  \n",
      "1   0.005735  \n",
      "2   0.011180  \n",
      "3   0.009183  \n",
      "4   0.009591  \n",
      "5   0.006715  \n",
      "6   0.006685  \n",
      "7   0.006454  \n",
      "8   0.007474  \n",
      "9   0.006807  \n",
      "10  0.007800  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results/0-0/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.018707  0.009907  0.000576  0.023993  0.882516  0.009850   \n",
      "1    Experiment2  0.016238  0.008548  0.000530  0.023031  0.891755  0.008550   \n",
      "2    Experiment3  0.017712  0.009334  0.000530  0.023019  0.891869  0.009326   \n",
      "3    Experiment4  0.016431  0.008629  0.000486  0.022036  0.900903  0.008652   \n",
      "4    Experiment5  0.020698  0.010986  0.000652  0.025535  0.866937  0.010898   \n",
      "5    Experiment6  0.017988  0.009598  0.000558  0.023629  0.886061  0.009471   \n",
      "6    Experiment7  0.014337  0.007560  0.000419  0.020471  0.914479  0.007549   \n",
      "7    Experiment8  0.020687  0.010824  0.000637  0.025232  0.870074  0.010893   \n",
      "8    Experiment9  0.022237  0.011608  0.000770  0.027742  0.842938  0.011708   \n",
      "9   Experiment10  0.020521  0.010747  0.000691  0.026290  0.858946  0.010805   \n",
      "10          Mean  0.018556  0.009774  0.000585  0.024098  0.880648  0.009770   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.012625  \n",
      "1   0.012118  \n",
      "2   0.012112  \n",
      "3   0.011595  \n",
      "4   0.013436  \n",
      "5   0.012433  \n",
      "6   0.010771  \n",
      "7   0.013276  \n",
      "8   0.014597  \n",
      "9   0.013833  \n",
      "10  0.012679  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results/1-1/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.021743  0.011890  0.000632  0.025134  0.926543  0.011702   \n",
      "1    Experiment2  0.019282  0.010418  0.000489  0.022111  0.943154  0.010377   \n",
      "2    Experiment3  0.013312  0.007198  0.000256  0.016009  0.970201  0.007164   \n",
      "3    Experiment4  0.022290  0.011901  0.000652  0.025525  0.924240  0.011996   \n",
      "4    Experiment5  0.015175  0.008250  0.000327  0.018073  0.962017  0.008167   \n",
      "5    Experiment6  0.012729  0.006914  0.000236  0.015365  0.972547  0.006850   \n",
      "6    Experiment7  0.020729  0.011259  0.000581  0.024096  0.932487  0.011156   \n",
      "7    Experiment8  0.025261  0.013676  0.000793  0.028164  0.907764  0.013595   \n",
      "8    Experiment9  0.019092  0.010283  0.000501  0.022391  0.941700  0.010275   \n",
      "9   Experiment10  0.027634  0.014968  0.000974  0.031215  0.886698  0.014872   \n",
      "10          Mean  0.019725  0.010676  0.000544  0.022808  0.936735  0.010615   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.013510  \n",
      "1   0.011885  \n",
      "2   0.008605  \n",
      "3   0.013720  \n",
      "4   0.009715  \n",
      "5   0.008259  \n",
      "6   0.012952  \n",
      "7   0.015139  \n",
      "8   0.012036  \n",
      "9   0.016779  \n",
      "10  0.012260  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results/2-2/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.017991  0.009901  0.000592  0.024338  0.916202  0.009639   \n",
      "1    Experiment2  0.019216  0.010502  0.000625  0.024996  0.911605  0.010296   \n",
      "2    Experiment3  0.018435  0.010273  0.000742  0.027245  0.894982  0.009877   \n",
      "3    Experiment4  0.018525  0.010214  0.000625  0.024992  0.911635  0.009925   \n",
      "4    Experiment5  0.018743  0.010265  0.000603  0.024561  0.914655  0.010042   \n",
      "5    Experiment6  0.016855  0.009262  0.000575  0.023984  0.918617  0.009031   \n",
      "6    Experiment7  0.016310  0.008966  0.000499  0.022333  0.929437  0.008738   \n",
      "7    Experiment8  0.017520  0.009625  0.000552  0.023489  0.921943  0.009387   \n",
      "8    Experiment9  0.017540  0.009696  0.000565  0.023774  0.920038  0.009398   \n",
      "9   Experiment10  0.019223  0.010460  0.000593  0.024355  0.916084  0.010299   \n",
      "10          Mean  0.018036  0.009916  0.000597  0.024407  0.915520  0.009663   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.013026  \n",
      "1   0.013379  \n",
      "2   0.014583  \n",
      "3   0.013377  \n",
      "4   0.013146  \n",
      "5   0.012837  \n",
      "6   0.011953  \n",
      "7   0.012572  \n",
      "8   0.012725  \n",
      "9   0.013036  \n",
      "10  0.013063  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results/3-3/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.046593  0.026609  0.003671  0.060585  0.523069  0.025540   \n",
      "1    Experiment2  0.046286  0.026527  0.003884  0.062323  0.495308  0.025372   \n",
      "2    Experiment3  0.040126  0.023052  0.003096  0.055638  0.597771  0.021995   \n",
      "3    Experiment4  0.059815  0.033879  0.005079  0.071267  0.340059  0.032788   \n",
      "4    Experiment5  0.047483  0.027083  0.003705  0.060866  0.518637  0.026028   \n",
      "5    Experiment6  0.055218  0.031535  0.005107  0.071464  0.336407  0.030268   \n",
      "6    Experiment7  0.038595  0.022160  0.002982  0.054608  0.612529  0.021156   \n",
      "7    Experiment8  0.043137  0.024833  0.003729  0.061067  0.515445  0.023646   \n",
      "8    Experiment9  0.039275  0.022517  0.002840  0.053287  0.631047  0.021529   \n",
      "9   Experiment10  0.057678  0.032675  0.004777  0.069116  0.379287  0.031617   \n",
      "10          Mean  0.047421  0.027087  0.003887  0.062022  0.494956  0.025994   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.033171  \n",
      "1   0.034123  \n",
      "2   0.030463  \n",
      "3   0.039020  \n",
      "4   0.033325  \n",
      "5   0.039128  \n",
      "6   0.029899  \n",
      "7   0.033436  \n",
      "8   0.029176  \n",
      "9   0.037843  \n",
      "10  0.033958  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results/4-4/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.011018  0.006055  0.000334  0.018281  0.929324  0.005868   \n",
      "1    Experiment2  0.011260  0.006226  0.000403  0.020071  0.914811  0.005997   \n",
      "2    Experiment3  0.013169  0.007300  0.000539  0.023213  0.886048  0.007014   \n",
      "3    Experiment4  0.012254  0.006812  0.000498  0.022320  0.894654  0.006526   \n",
      "4    Experiment5  0.011692  0.006430  0.000329  0.018128  0.930502  0.006227   \n",
      "5    Experiment6  0.010655  0.005857  0.000305  0.017473  0.935437  0.005675   \n",
      "6    Experiment7  0.013893  0.007617  0.000499  0.022339  0.894471  0.007399   \n",
      "7    Experiment8  0.011582  0.006425  0.000438  0.020931  0.907349  0.006169   \n",
      "8    Experiment9  0.010438  0.005773  0.000342  0.018493  0.927683  0.005559   \n",
      "9   Experiment10  0.010856  0.005976  0.000328  0.018105  0.930679  0.005782   \n",
      "10          Mean  0.011682  0.006447  0.000401  0.019935  0.915096  0.006222   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.009730  \n",
      "1   0.010682  \n",
      "2   0.012355  \n",
      "3   0.011879  \n",
      "4   0.009649  \n",
      "5   0.009300  \n",
      "6   0.011890  \n",
      "7   0.011140  \n",
      "8   0.009842  \n",
      "9   0.009636  \n",
      "10  0.010610  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results/5-5/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the new experiment\n",
    "experiments_path_newphysics = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results\"\n",
    "\n",
    "experiments_path_newphysicss = [os.path.join(experiments_path_newphysics, f\"{i}-{i}\") for i in range(6)]\n",
    "\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiments_path_newphysics in experiments_path_newphysicss:\n",
    "    # Initialize lists to store metrics for each experiment\n",
    "    mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "    for experiment in experiments:\n",
    "        true_label_path = os.path.join(experiments_path_newphysics, experiment, 'true_label.npy')\n",
    "        pred_label_path = os.path.join(experiments_path_newphysics, experiment, 'pred_label.npy')\n",
    "        \n",
    "        # Calculate metrics for the current experiment\n",
    "        metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "        \n",
    "        mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        mape_list.append(mape)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "        l1_list.append(l1)\n",
    "        l2_list.append(l2)\n",
    "\n",
    "    # Create a DataFrame to store the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Experiment': experiments,\n",
    "        'MSE': mse_list,\n",
    "        'MAE': mae_list,\n",
    "        'MAPE': mape_list,\n",
    "        'RMSE': rmse_list,\n",
    "        'R^2': r2_list,\n",
    "        'L1 Error': l1_list,\n",
    "        'L2 Error': l2_list\n",
    "    })\n",
    "\n",
    "    # Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "    mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "    # Append the mean values to the DataFrame\n",
    "    mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "    mean_values_df['Experiment'] = 'Mean'\n",
    "    metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "    # Print the results\n",
    "    print(metrics_df)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    output_csv_path = os.path.join(experiments_path_newphysics, 'metrics_summary.csv')\n",
    "    metrics_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Metrics summary saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.028769  0.016639  0.001952  0.044186  0.746310  0.015770   \n",
      "1    Experiment2  0.038125  0.021976  0.002982  0.054604  0.612579  0.020898   \n",
      "2    Experiment3  0.055501  0.031601  0.004821  0.069435  0.373558  0.030423   \n",
      "3    Experiment4  0.058010  0.033028  0.005342  0.073089  0.305878  0.031798   \n",
      "4    Experiment5  0.035050  0.020210  0.002588  0.050871  0.663740  0.019213   \n",
      "5    Experiment6  0.027284  0.015768  0.001843  0.042926  0.760578  0.014956   \n",
      "6    Experiment7  0.026157  0.015135  0.001703  0.041268  0.778718  0.014338   \n",
      "7    Experiment8  0.044147  0.025280  0.003461  0.058828  0.550324  0.024199   \n",
      "8    Experiment9  0.051641  0.029514  0.004496  0.067053  0.415797  0.028307   \n",
      "9   Experiment10  0.040056  0.023046  0.003153  0.056152  0.590308  0.021957   \n",
      "10          Mean  0.040474  0.023220  0.003234  0.055841  0.579779  0.022186   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.024193  \n",
      "1   0.029897  \n",
      "2   0.038017  \n",
      "3   0.040018  \n",
      "4   0.027853  \n",
      "5   0.023503  \n",
      "6   0.022595  \n",
      "7   0.032210  \n",
      "8   0.036713  \n",
      "9   0.030744  \n",
      "10  0.030574  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results2/4-4/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/Users/jonathanzha/Desktop/AttenPASOH\")\n",
    "from utils.util import eval_metrix  # Assuming this function exists and is correctly implemented\n",
    "# Define the path to the new experiment\n",
    "experiments_path = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU-attenPASOH(newPhysics+25weight) results2/4-4\"\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "# Initialize lists to store metrics for each experiment\n",
    "mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiment in experiments:\n",
    "    true_label_path = os.path.join(experiments_path, experiment, 'true_label.npy')\n",
    "    pred_label_path = os.path.join(experiments_path, experiment, 'pred_label.npy')\n",
    "    \n",
    "    # Calculate metrics for the current experiment\n",
    "    metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "    \n",
    "    mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "    mape_list.append(mape)\n",
    "    rmse_list.append(rmse)\n",
    "    r2_list.append(r2)\n",
    "    l1_list.append(l1)\n",
    "    l2_list.append(l2)\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Experiment': experiments,\n",
    "    'MSE': mse_list,\n",
    "    'MAE': mae_list,\n",
    "    'MAPE': mape_list,\n",
    "    'RMSE': rmse_list,\n",
    "    'R^2': r2_list,\n",
    "    'L1 Error': l1_list,\n",
    "    'L2 Error': l2_list\n",
    "})\n",
    "\n",
    "# Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "# Append the mean values to the DataFrame\n",
    "mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "mean_values_df['Experiment'] = 'Mean'\n",
    "metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "# Print the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_csv_path = os.path.join(experiments_path, 'metrics_summary.csv')\n",
    "metrics_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Metrics summary saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.006766  0.007522  0.000098  0.009906  0.958793  0.007229   \n",
      "1    Experiment2  0.006028  0.006738  0.000095  0.009738  0.960179  0.006440   \n",
      "2    Experiment3  0.007892  0.008740  0.000115  0.010737  0.951587  0.008432   \n",
      "3    Experiment4  0.005189  0.005750  0.000059  0.007672  0.975286  0.005544   \n",
      "4    Experiment5  0.008841  0.009917  0.000156  0.012482  0.934569  0.009446   \n",
      "5    Experiment6  0.024052  0.026335  0.000692  0.026311  0.709286  0.025697   \n",
      "6    Experiment7  0.005455  0.006008  0.000069  0.008311  0.970992  0.005828   \n",
      "7    Experiment8  0.006774  0.007452  0.000082  0.009037  0.965705  0.007237   \n",
      "8    Experiment9  0.004518  0.005068  0.000063  0.007909  0.973735  0.004827   \n",
      "9   Experiment10  0.007289  0.008026  0.000108  0.010371  0.954837  0.007788   \n",
      "10          Mean  0.008280  0.009156  0.000154  0.011247  0.935497  0.008847   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.010569  \n",
      "1   0.010390  \n",
      "2   0.011456  \n",
      "3   0.008185  \n",
      "4   0.013318  \n",
      "5   0.028073  \n",
      "6   0.008868  \n",
      "7   0.009642  \n",
      "8   0.008438  \n",
      "9   0.011065  \n",
      "10  0.012001  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(Baseline) results/0-0/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.011298  0.012136  0.000181  0.013461  0.857095  0.012037   \n",
      "1    Experiment2  0.011300  0.011975  0.000172  0.013121  0.864229  0.012039   \n",
      "2    Experiment3  0.010779  0.011548  0.000167  0.012913  0.868487  0.011484   \n",
      "3    Experiment4  0.011453  0.012147  0.000176  0.013278  0.860948  0.012202   \n",
      "4    Experiment5  0.010623  0.011331  0.000157  0.012545  0.875885  0.011318   \n",
      "5    Experiment6  0.011125  0.011899  0.000171  0.013091  0.864838  0.011852   \n",
      "6    Experiment7  0.011821  0.012675  0.000188  0.013700  0.851970  0.012594   \n",
      "7    Experiment8  0.011616  0.012511  0.000195  0.013964  0.846218  0.012375   \n",
      "8    Experiment9  0.012111  0.012980  0.000192  0.013854  0.848627  0.012903   \n",
      "9   Experiment10  0.011396  0.012199  0.000179  0.013372  0.858985  0.012141   \n",
      "10          Mean  0.011352  0.012140  0.000178  0.013330  0.859728  0.012095   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.014331  \n",
      "1   0.013969  \n",
      "2   0.013748  \n",
      "3   0.014137  \n",
      "4   0.013356  \n",
      "5   0.013938  \n",
      "6   0.014586  \n",
      "7   0.014867  \n",
      "8   0.014750  \n",
      "9   0.014236  \n",
      "10  0.014192  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(Baseline) results/1-1/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.007881  0.008343  0.000101  0.010067  0.952142  0.008349   \n",
      "1    Experiment2  0.010187  0.010715  0.000165  0.012854  0.921969  0.010794   \n",
      "2    Experiment3  0.009857  0.010531  0.000154  0.012425  0.927090  0.010443   \n",
      "3    Experiment4  0.007727  0.008267  0.000104  0.010174  0.951114  0.008187   \n",
      "4    Experiment5  0.007880  0.008381  0.000101  0.010060  0.952208  0.008349   \n",
      "5    Experiment6  0.008913  0.009471  0.000130  0.011386  0.938781  0.009444   \n",
      "6    Experiment7  0.009106  0.009588  0.000134  0.011585  0.936619  0.009648   \n",
      "7    Experiment8  0.010085  0.010796  0.000168  0.012970  0.920559  0.010685   \n",
      "8    Experiment9  0.007445  0.007980  0.000094  0.009706  0.955508  0.007888   \n",
      "9   Experiment10  0.008503  0.009068  0.000114  0.010668  0.946257  0.009009   \n",
      "10          Mean  0.008758  0.009314  0.000127  0.011189  0.940225  0.009280   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.010653  \n",
      "1   0.013603  \n",
      "2   0.013149  \n",
      "3   0.010767  \n",
      "4   0.010646  \n",
      "5   0.012049  \n",
      "6   0.012260  \n",
      "7   0.013725  \n",
      "8   0.010272  \n",
      "9   0.011289  \n",
      "10  0.011841  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(Baseline) results/2-2/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.007959  0.008881  0.000149  0.012215  0.930811  0.008460   \n",
      "1    Experiment2  0.008385  0.009301  0.000158  0.012559  0.926855  0.008914   \n",
      "2    Experiment3  0.006252  0.006897  0.000094  0.009707  0.956305  0.006646   \n",
      "3    Experiment4  0.007857  0.008664  0.000131  0.011455  0.939154  0.008352   \n",
      "4    Experiment5  0.007213  0.007925  0.000117  0.010803  0.945877  0.007668   \n",
      "5    Experiment6  0.006044  0.006681  0.000097  0.009869  0.954834  0.006425   \n",
      "6    Experiment7  0.006909  0.007654  0.000119  0.010921  0.944696  0.007344   \n",
      "7    Experiment8  0.007227  0.008018  0.000125  0.011176  0.942078  0.007683   \n",
      "8    Experiment9  0.006890  0.007426  0.000095  0.009758  0.955844  0.007325   \n",
      "9   Experiment10  0.007477  0.008307  0.000140  0.011812  0.935297  0.007948   \n",
      "10          Mean  0.007221  0.007975  0.000123  0.011027  0.943175  0.007677   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.012969  \n",
      "1   0.013335  \n",
      "2   0.010306  \n",
      "3   0.012162  \n",
      "4   0.011471  \n",
      "5   0.010479  \n",
      "6   0.011595  \n",
      "7   0.011866  \n",
      "8   0.010361  \n",
      "9   0.012542  \n",
      "10  0.011709  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(Baseline) results/3-3/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.009434  0.010329  0.000185  0.013598  0.817681  0.010035   \n",
      "1    Experiment2  0.009368  0.010281  0.000179  0.013389  0.823256  0.009965   \n",
      "2    Experiment3  0.015704  0.016976  0.000378  0.019453  0.626899  0.016705   \n",
      "3    Experiment4  0.013558  0.014703  0.000332  0.018211  0.673012  0.014423   \n",
      "4    Experiment5  0.011321  0.012280  0.000211  0.014524  0.792016  0.012044   \n",
      "5    Experiment6  0.009233  0.010153  0.000179  0.013377  0.823567  0.009822   \n",
      "6    Experiment7  0.009741  0.010629  0.000188  0.013726  0.814229  0.010362   \n",
      "7    Experiment8  0.010569  0.011592  0.000227  0.015050  0.776670  0.011243   \n",
      "8    Experiment9  0.008237  0.009051  0.000140  0.011827  0.862077  0.008763   \n",
      "9   Experiment10  0.009338  0.010274  0.000187  0.013661  0.816002  0.009934   \n",
      "10          Mean  0.010650  0.011627  0.000221  0.014682  0.782541  0.011330   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.014457  \n",
      "1   0.014235  \n",
      "2   0.020682  \n",
      "3   0.019362  \n",
      "4   0.015442  \n",
      "5   0.014222  \n",
      "6   0.014594  \n",
      "7   0.016001  \n",
      "8   0.012575  \n",
      "9   0.014524  \n",
      "10  0.015609  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(Baseline) results/4-4/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.006119  0.006681  0.000106  0.010286  0.916298  0.006466   \n",
      "1    Experiment2  0.007022  0.007656  0.000149  0.012210  0.882063  0.007421   \n",
      "2    Experiment3  0.006400  0.006989  0.000115  0.010702  0.909393  0.006764   \n",
      "3    Experiment4  0.005761  0.006280  0.000108  0.010404  0.914366  0.006088   \n",
      "4    Experiment5  0.006328  0.006923  0.000117  0.010829  0.907224  0.006688   \n",
      "5    Experiment6  0.006538  0.007142  0.000117  0.010830  0.907213  0.006909   \n",
      "6    Experiment7  0.005881  0.006414  0.000103  0.010146  0.918554  0.006215   \n",
      "7    Experiment8  0.005924  0.006482  0.000105  0.010268  0.916594  0.006261   \n",
      "8    Experiment9  0.006853  0.007530  0.000164  0.012808  0.870210  0.007242   \n",
      "9   Experiment10  0.006119  0.006696  0.000113  0.010647  0.910313  0.006466   \n",
      "10          Mean  0.006294  0.006879  0.000120  0.010913  0.905223  0.006652   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.010862  \n",
      "1   0.012894  \n",
      "2   0.011301  \n",
      "3   0.010987  \n",
      "4   0.011436  \n",
      "5   0.011437  \n",
      "6   0.010715  \n",
      "7   0.010843  \n",
      "8   0.013526  \n",
      "9   0.011244  \n",
      "10  0.011524  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(Baseline) results/5-5/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the new experiment\n",
    "experiments_path_baseline = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(Baseline) results\"\n",
    "\n",
    "experiments_path_baselines = [os.path.join(experiments_path_baseline, f\"{i}-{i}\") for i in range(6)]\n",
    "\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiments_path_baseline in experiments_path_baselines:\n",
    "    # Initialize lists to store metrics for each experiment\n",
    "    mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "    for experiment in experiments:\n",
    "        true_label_path = os.path.join(experiments_path_baseline, experiment, 'true_label.npy')\n",
    "        pred_label_path = os.path.join(experiments_path_baseline, experiment, 'pred_label.npy')\n",
    "        \n",
    "        # Calculate metrics for the current experiment\n",
    "        metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "        \n",
    "        mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        mape_list.append(mape)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "        l1_list.append(l1)\n",
    "        l2_list.append(l2)\n",
    "\n",
    "    # Create a DataFrame to store the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Experiment': experiments,\n",
    "        'MSE': mse_list,\n",
    "        'MAE': mae_list,\n",
    "        'MAPE': mape_list,\n",
    "        'RMSE': rmse_list,\n",
    "        'R^2': r2_list,\n",
    "        'L1 Error': l1_list,\n",
    "        'L2 Error': l2_list\n",
    "    })\n",
    "\n",
    "    # Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "    mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "    # Append the mean values to the DataFrame\n",
    "    mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "    mean_values_df['Experiment'] = 'Mean'\n",
    "    metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "    # Print the results\n",
    "    print(metrics_df)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    output_csv_path = os.path.join(experiments_path_baseline, 'metrics_summary.csv')\n",
    "    metrics_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Metrics summary saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AttenPASOH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

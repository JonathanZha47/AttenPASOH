{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/Users/jonathanzha/Desktop/AttenPASOH\")\n",
    "from utils.util import eval_metrix  # Assuming this function exists and is correctly implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.029845  0.032070  0.001210  0.034780  0.502427  0.031904   \n",
      "1    Experiment2  0.021661  0.023377  0.000723  0.026895  0.702462  0.023155   \n",
      "2    Experiment3  0.021634  0.023305  0.000701  0.026477  0.711642  0.023126   \n",
      "3    Experiment4  0.018777  0.020186  0.000516  0.022726  0.787557  0.020072   \n",
      "4    Experiment5  0.030212  0.032208  0.001381  0.037163  0.431910  0.032296   \n",
      "5    Experiment6  0.030300  0.032646  0.001454  0.038131  0.401922  0.032390   \n",
      "6    Experiment7  0.019531  0.020989  0.000616  0.024820  0.746613  0.020878   \n",
      "7    Experiment8  0.031654  0.034024  0.001536  0.039189  0.368288  0.033837   \n",
      "8    Experiment9  0.028010  0.030034  0.001130  0.033609  0.535366  0.029941   \n",
      "9   Experiment10  0.032214  0.034501  0.001708  0.041329  0.297410  0.034436   \n",
      "10          Mean  0.026384  0.028334  0.001097  0.032512  0.548560  0.028203   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.037127  \n",
      "1   0.028710  \n",
      "2   0.028264  \n",
      "3   0.024260  \n",
      "4   0.039671  \n",
      "5   0.040704  \n",
      "6   0.026494  \n",
      "7   0.041833  \n",
      "8   0.035877  \n",
      "9   0.044118  \n",
      "10  0.034706  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(lstm) results/0-0/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.011756  0.012537  0.000223  0.014936  0.830082  0.012530   \n",
      "1    Experiment2  0.011850  0.012716  0.000231  0.015187  0.824312  0.012630   \n",
      "2    Experiment3  0.011851  0.012695  0.000224  0.014973  0.829222  0.012631   \n",
      "3    Experiment4  0.012356  0.013250  0.000228  0.015092  0.826512  0.013170   \n",
      "4    Experiment5  0.011276  0.012063  0.000220  0.014829  0.832494  0.012019   \n",
      "5    Experiment6  0.012576  0.013488  0.000245  0.015666  0.813053  0.013405   \n",
      "6    Experiment7  0.011125  0.011917  0.000210  0.014493  0.840006  0.011858   \n",
      "7    Experiment8  0.011812  0.012604  0.000218  0.014777  0.833665  0.012590   \n",
      "8    Experiment9  0.011058  0.011867  0.000213  0.014583  0.838021  0.011786   \n",
      "9   Experiment10  0.010950  0.011674  0.000202  0.014211  0.846165  0.011671   \n",
      "10          Mean  0.011661  0.012481  0.000221  0.014875  0.831353  0.012429   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.015907  \n",
      "1   0.016175  \n",
      "2   0.015948  \n",
      "3   0.016074  \n",
      "4   0.015794  \n",
      "5   0.016685  \n",
      "6   0.015436  \n",
      "7   0.015739  \n",
      "8   0.015531  \n",
      "9   0.015136  \n",
      "10  0.015843  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(lstm) results/1-1/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.010874  0.011555  0.000219  0.014800  0.898621  0.011525   \n",
      "1    Experiment2  0.011072  0.011753  0.000204  0.014268  0.905775  0.011735   \n",
      "2    Experiment3  0.009651  0.010183  0.000168  0.012965  0.922210  0.010228   \n",
      "3    Experiment4  0.008389  0.008936  0.000136  0.011683  0.936834  0.008891   \n",
      "4    Experiment5  0.007198  0.007675  0.000105  0.010232  0.951543  0.007628   \n",
      "5    Experiment6  0.010119  0.010777  0.000180  0.013422  0.916622  0.010725   \n",
      "6    Experiment7  0.007670  0.008182  0.000126  0.011231  0.941619  0.008129   \n",
      "7    Experiment8  0.010372  0.011006  0.000179  0.013369  0.917276  0.010992   \n",
      "8    Experiment9  0.014587  0.015390  0.000341  0.018470  0.842119  0.015460   \n",
      "9   Experiment10  0.009281  0.009878  0.000151  0.012291  0.930088  0.009836   \n",
      "10          Mean  0.009921  0.010534  0.000181  0.013273  0.916271  0.010515   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.015667  \n",
      "1   0.015104  \n",
      "2   0.013724  \n",
      "3   0.012367  \n",
      "4   0.010831  \n",
      "5   0.014208  \n",
      "6   0.011889  \n",
      "7   0.014152  \n",
      "8   0.019551  \n",
      "9   0.013010  \n",
      "10  0.014050  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(lstm) results/2-2/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.006919  0.007541  0.000112  0.010578  0.948923  0.007357   \n",
      "1    Experiment2  0.007745  0.008438  0.000129  0.011356  0.941127  0.008236   \n",
      "2    Experiment3  0.008463  0.009252  0.000151  0.012306  0.930872  0.008999   \n",
      "3    Experiment4  0.007164  0.007789  0.000118  0.010878  0.945987  0.007618   \n",
      "4    Experiment5  0.006772  0.007366  0.000100  0.010000  0.954354  0.007202   \n",
      "5    Experiment6  0.008549  0.009416  0.000154  0.012415  0.929640  0.009091   \n",
      "6    Experiment7  0.007962  0.008644  0.000133  0.011548  0.939122  0.008467   \n",
      "7    Experiment8  0.006715  0.007367  0.000102  0.010123  0.953222  0.007141   \n",
      "8    Experiment9  0.006965  0.007637  0.000109  0.010435  0.950290  0.007406   \n",
      "9   Experiment10  0.007863  0.008533  0.000131  0.011447  0.940189  0.008361   \n",
      "10          Mean  0.007512  0.008198  0.000124  0.011109  0.943373  0.007988   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.011235  \n",
      "1   0.012062  \n",
      "2   0.013070  \n",
      "3   0.011553  \n",
      "4   0.010621  \n",
      "5   0.013186  \n",
      "6   0.012265  \n",
      "7   0.010751  \n",
      "8   0.011083  \n",
      "9   0.012157  \n",
      "10  0.011798  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(lstm) results/3-3/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.020686  0.022175  0.000806  0.028384  0.252102  0.022023   \n",
      "1    Experiment2  0.022132  0.023771  0.000912  0.030198  0.153465  0.023563   \n",
      "2    Experiment3  0.018257  0.019726  0.000670  0.025890  0.377746  0.019437   \n",
      "3    Experiment4  0.023379  0.025092  0.000909  0.030144  0.156476  0.024890   \n",
      "4    Experiment5  0.016144  0.017457  0.000653  0.025559  0.393566  0.017188   \n",
      "5    Experiment6  0.018705  0.020094  0.000675  0.025989  0.372968  0.019914   \n",
      "6    Experiment7  0.019432  0.020951  0.000764  0.027643  0.290626  0.020688   \n",
      "7    Experiment8  0.021222  0.022759  0.000774  0.027822  0.281407  0.022594   \n",
      "8    Experiment9  0.017707  0.019137  0.000636  0.025217  0.409682  0.018852   \n",
      "9   Experiment10  0.021738  0.023291  0.000822  0.028666  0.237183  0.023143   \n",
      "10          Mean  0.019940  0.021445  0.000762  0.027551  0.292522  0.021229   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.030200  \n",
      "1   0.032130  \n",
      "2   0.027547  \n",
      "3   0.032073  \n",
      "4   0.027195  \n",
      "5   0.027653  \n",
      "6   0.029412  \n",
      "7   0.029603  \n",
      "8   0.026831  \n",
      "9   0.030500  \n",
      "10  0.029314  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(lstm) results/4-4/metrics_summary.csv\n",
      "      Experiment       MSE       MAE      MAPE      RMSE       R^2  L1 Error  \\\n",
      "0    Experiment1  0.009956  0.010785  0.000195  0.013966  0.848405  0.010524   \n",
      "1    Experiment2  0.011668  0.012596  0.000239  0.015472  0.813971  0.012333   \n",
      "2    Experiment3  0.011773  0.012718  0.000241  0.015526  0.812672  0.012444   \n",
      "3    Experiment4  0.010414  0.011276  0.000204  0.014271  0.841720  0.011008   \n",
      "4    Experiment5  0.010170  0.011030  0.000205  0.014305  0.840962  0.010750   \n",
      "5    Experiment6  0.009982  0.010782  0.000181  0.013443  0.859555  0.010551   \n",
      "6    Experiment7  0.009899  0.010713  0.000189  0.013750  0.853062  0.010463   \n",
      "7    Experiment8  0.010850  0.011710  0.000210  0.014477  0.837115  0.011469   \n",
      "8    Experiment9  0.009604  0.010424  0.000185  0.013604  0.856181  0.010152   \n",
      "9   Experiment10  0.008938  0.009676  0.000160  0.012630  0.876026  0.009448   \n",
      "10          Mean  0.010325  0.011171  0.000201  0.014144  0.843967  0.010914   \n",
      "\n",
      "    L2 Error  \n",
      "0   0.014752  \n",
      "1   0.016342  \n",
      "2   0.016399  \n",
      "3   0.015074  \n",
      "4   0.015110  \n",
      "5   0.014199  \n",
      "6   0.014524  \n",
      "7   0.015292  \n",
      "8   0.014369  \n",
      "9   0.013341  \n",
      "10  0.014940  \n",
      "Metrics summary saved to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(lstm) results/5-5/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the new experiment\n",
    "experiments_path_lstm = \"/Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(lstm) results\"\n",
    "\n",
    "# add 0-0 to 5-5 to the path, iterate from /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(GRU) results/0-0 to /Users/jonathanzha/Desktop/AttenPASOH/results of reviewer/XJTU(GRU) results/5-5\n",
    "experiments_path_lstms = [os.path.join(experiments_path_lstm, f\"{i}-{i}\") for i in range(6)]\n",
    "\n",
    "experiments = [f\"Experiment{i+1}\" for i in range(10)]\n",
    "\n",
    "def calculate_metrics(true_label_path, pred_label_path):\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Calculate metrics using the eval_matrix function\n",
    "    mse, mae, mape, rmse, r2, l1, l2 = eval_metrix(true_label, pred_label)\n",
    "    \n",
    "    return mse, mae, mape, rmse, r2, l1, l2\n",
    "\n",
    "# Loop over each experiment\n",
    "for experiments_path_lstm in experiments_path_lstms:\n",
    "    # Initialize lists to store metrics for each experiment\n",
    "    mse_list, mae_list, mape_list, rmse_list, r2_list, l1_list, l2_list = [], [], [], [], [], [], []\n",
    "\n",
    "    for experiment in experiments:\n",
    "        true_label_path = os.path.join(experiments_path_lstm, experiment, 'true_label.npy')\n",
    "        pred_label_path = os.path.join(experiments_path_lstm, experiment, 'pred_label.npy')\n",
    "        \n",
    "        # Calculate metrics for the current experiment\n",
    "        metrics = calculate_metrics(true_label_path, pred_label_path)\n",
    "        \n",
    "        mse, mae, mape, rmse, r2, l1, l2 = metrics\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        mape_list.append(mape)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "        l1_list.append(l1)\n",
    "        l2_list.append(l2)\n",
    "\n",
    "    # Create a DataFrame to store the metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Experiment': experiments,\n",
    "        'MSE': mse_list,\n",
    "        'MAE': mae_list,\n",
    "        'MAPE': mape_list,\n",
    "        'RMSE': rmse_list,\n",
    "        'R^2': r2_list,\n",
    "        'L1 Error': l1_list,\n",
    "        'L2 Error': l2_list\n",
    "    })\n",
    "\n",
    "    # Calculate the mean values across all numeric columns (excluding 'Experiment')\n",
    "    mean_values = metrics_df.drop(columns=['Experiment']).mean(axis=0)\n",
    "\n",
    "    # Append the mean values to the DataFrame\n",
    "    mean_values_df = pd.DataFrame(mean_values).transpose()\n",
    "    mean_values_df['Experiment'] = 'Mean'\n",
    "    metrics_df = pd.concat([metrics_df, mean_values_df], ignore_index=True)\n",
    "\n",
    "    # Print the results\n",
    "    print(metrics_df)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    output_csv_path = os.path.join(experiments_path_lstm, 'metrics_summary.csv')\n",
    "    metrics_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Metrics summary saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AttenPASOH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
